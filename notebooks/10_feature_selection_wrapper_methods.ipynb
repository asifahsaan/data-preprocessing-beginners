{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifahsaan/data-preprocessing-beginners/blob/main/notebooks/10_feature_selection_wrapper_methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf1f46d",
      "metadata": {
        "id": "2bf1f46d"
      },
      "source": [
        "# 10 — Feature Selection: Wrapper Methods\n",
        "In this notebook, we'll explore **wrapper-based feature selection** — where feature subsets are selected based on model performance.\n",
        "\n",
        "We'll cover:\n",
        "- What wrapper methods are and how they differ\n",
        "- Recursive Feature Elimination (RFE)\n",
        "- RFE + Cross-Validation (RFECV)\n",
        "- Pipeline integration for clean workflows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b70702a",
      "metadata": {
        "id": "0b70702a"
      },
      "source": [
        "## 1. What Are Wrapper Methods?\n",
        "**Wrapper methods** use a predictive model to evaluate which feature subsets work best. Unlike filter methods, they consider feature interactions and model accuracy.\n",
        "\n",
        "Common techniques:\n",
        "- `RFE` (Recursive Feature Elimination): Iteratively removes least important features\n",
        "- `RFECV`: Combines RFE with cross-validation to choose the best number of features\n",
        "\n",
        "⚠️ **Note**: These are more computationally expensive than filter methods."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af149a46",
      "metadata": {
        "id": "af149a46"
      },
      "source": [
        "## 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35930e87",
      "metadata": {
        "id": "35930e87"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "# Load toy dataset\n",
        "X_data = load_breast_cancer()\n",
        "X = pd.DataFrame(X_data.data, columns=X_data.feature_names)\n",
        "y = X_data.target\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9258be7",
      "metadata": {
        "id": "f9258be7"
      },
      "source": [
        "## 3. Recursive Feature Elimination (RFE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49f1bdf",
      "metadata": {
        "id": "c49f1bdf"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)\n",
        "X_rfe = rfe.fit_transform(X, y)\n",
        "\n",
        "selected_features = X.columns[rfe.support_]\n",
        "print(\"Selected Features:\", selected_features.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6ae9d04",
      "metadata": {
        "id": "f6ae9d04"
      },
      "source": [
        "## 4. RFECV — RFE + Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f051a77e",
      "metadata": {
        "id": "f051a77e"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "rfecv = RFECV(estimator=model, cv=cv)\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "best_features = X.columns[rfecv.support_]\n",
        "print(\"Optimal features selected by RFECV:\", best_features.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b31435b",
      "metadata": {
        "id": "8b31435b"
      },
      "source": [
        "## 5. Visualize RFECV Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ff5cff1",
      "metadata": {
        "id": "3ff5cff1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.xlabel(\"Number of Features Selected\")\n",
        "plt.ylabel(\"Cross-Validation Score\")\n",
        "plt.title(\"RFECV Feature Selection\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "940ee60d",
      "metadata": {
        "id": "940ee60d"
      },
      "source": [
        "## 6. Use RFE in a Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5eba7a7",
      "metadata": {
        "id": "a5eba7a7"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "rfe_pipeline = Pipeline([\n",
        "    (\"feature_selection\", RFE(estimator=LogisticRegression(max_iter=500), n_features_to_select=5)),\n",
        "    (\"classifier\", LogisticRegression(max_iter=500))\n",
        "])\n",
        "\n",
        "rfe_pipeline.fit(X, y)\n",
        "print(\"Pipeline trained with RFE-selected features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f67044",
      "metadata": {
        "id": "77f67044"
      },
      "source": [
        "## Summary\n",
        "- Wrapper methods evaluate feature subsets using model performance.\n",
        "- `RFE` removes least useful features iteratively.\n",
        "- `RFECV` automates feature count using cross-validation.\n",
        "- Pipelines keep wrapper selection integrated and reusable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06d77355",
      "metadata": {
        "id": "06d77355"
      },
      "source": [
        "## What’s Next?\n",
        "In the next notebook:\n",
        "**`11_feature_selection_embedded_methods.ipynb`**\n",
        "We'll explore **embedded methods** that perform selection during model training — such as L1 (Lasso), Decision Trees, and Ensemble Models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}