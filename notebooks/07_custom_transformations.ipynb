{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJKVe/j0tJwm8qUj4fpNlJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 07 ‚Äî Custom Feature Transformations\n",
        "üìÅ File name: 07_custom_transformations.ipynb\n",
        "\n",
        "This notebook teaches how to apply custom logic to your data using:\n",
        "\n",
        " - FunctionTransformer ‚Äî for quick functions\n",
        "\n",
        " - Custom classes ‚Äî for reusable, modular transformations\n",
        "It‚Äôs ideal for when built-in transformers don‚Äôt meet your specific needs.\n",
        "\n",
        "üìí Notebook Sections\n",
        "1. Title & Intro\n",
        "2. When Custom Transformations Are Needed\n",
        "3. FunctionTransformer (Lambda-style)\n",
        "4. Custom Transformer (Class-based)\n",
        "5. Use in sklearn Pipeline\n",
        "6. Summary & What‚Äôs Next"
      ],
      "metadata": {
        "id": "5AK5eQsDuxDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Title & Introduction (Markdown)\n",
        "### 07 ‚Äî Custom Feature Transformations\n",
        "\n",
        "In this notebook, we‚Äôll learn how to build **custom transformers** to apply your own logic during preprocessing.\n",
        "\n",
        "We‚Äôll use:\n",
        "\n",
        "- `FunctionTransformer` for simple functions  \n",
        "- Custom Python classes for more flexible logic  \n",
        "- Integration with `Pipeline` to keep things modular\n",
        "\n",
        "## 2. When Do You Need Custom Transforms? (Markdown)\n",
        "###  Why Use Custom Transformations?\n",
        "\n",
        "Built-in tools like `StandardScaler` or `PolynomialFeatures` are great ‚Äî but sometimes you need:\n",
        "\n",
        "- Domain-specific rules (e.g. log1p of skewed features)\n",
        "- External feature mapping (e.g. map zip codes to regions)\n",
        "- Combined transformations across multiple columns\n",
        "\n",
        "That‚Äôs when custom transformers shine.\n"
      ],
      "metadata": {
        "id": "vUue1RPCvFZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. FunctionTransformer ‚Äî Quick Example"
      ],
      "metadata": {
        "id": "vNFxwOCxv6Pw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl9L1r8HuXXW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"../data/sample_data.csv\")\n",
        "\n",
        "# Apply log1p (log(x + 1)) to skewed numeric column\n",
        "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
        "\n",
        "df[\"Income_log\"] = log_transformer.fit_transform(df[[\"Income\"]])\n",
        "df[[\"Income\", \"Income_log\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Build a Custom Transformer Class"
      ],
      "metadata": {
        "id": "OzFCTaaPv3rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ColumnDifference(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom transformer to compute the difference between two columns\n",
        "    \"\"\"\n",
        "    def __init__(self, col1, col2, new_col_name=\"diff\"):\n",
        "        self.col1 = col1\n",
        "        self.col2 = col2\n",
        "        self.new_col_name = new_col_name\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_copy = X.copy()\n",
        "        X_copy[self.new_col_name] = X_copy[self.col1] - X_copy[self.col2]\n",
        "        return X_copy"
      ],
      "metadata": {
        "id": "FPd_tYE_vRI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Income - Expenses ‚Üí Net Income\n",
        "custom_diff = ColumnDifference(col1=\"Income\", col2=\"Expenses\", new_col_name=\"NetIncome\")\n",
        "df_transformed = custom_diff.fit_transform(df)\n",
        "\n",
        "df_transformed[[\"Income\", \"Expenses\", \"NetIncome\"]].head()"
      ],
      "metadata": {
        "id": "b7HomNb3vVOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Use in Pipeline"
      ],
      "metadata": {
        "id": "efAE-Aocv0KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Combine log transform + custom difference\n",
        "pipeline = Pipeline([\n",
        "    (\"log_income\", FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\")),\n",
        "    (\"net_income\", ColumnDifference(col1=\"Income\", col2=\"Expenses\", new_col_name=\"NetIncome\"))\n",
        "])\n",
        "\n",
        "# NOTE: FunctionTransformer in a pipeline will need a selector or ColumnTransformer wrapper."
      ],
      "metadata": {
        "id": "gN8kF26VvXsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Summary & What‚Äôs Next (Markdown)\n",
        "### Summary\n",
        "\n",
        "In this notebook, we:\n",
        "\n",
        "- Used `FunctionTransformer` for quick transformations like `log1p`\n",
        "- Built a custom class to compute column differences\n",
        "- Prepared these for integration into pipelines\n",
        "\n",
        "**Next Up**: `08_dimensionality_reduction.ipynb`  \n",
        "We‚Äôll explore how to reduce feature count using **PCA** and **TSNE**.\n"
      ],
      "metadata": {
        "id": "lq0xNEi3vaog"
      }
    }
  ]
}