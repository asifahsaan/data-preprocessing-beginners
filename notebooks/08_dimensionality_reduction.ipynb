{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf9hnTy9XW/RDARVBv+E5v"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook 08 ‚Äî Dimensionality Reduction\n",
        "üìÅ File name: 08_dimensionality_reduction.ipynb\n",
        "\n",
        "This notebook shows how to reduce the number of features in a dataset using two common dimensionality reduction techniques:\n",
        "\n",
        "- **Principal Component Analysis (PCA)** ‚Äî a linear method to transform high-dimensional data into a smaller set of components while preserving as much variance as possible.\n",
        "\n",
        "- **T-distributed Stochastic Neighbor Embedding (TSNE)** ‚Äî a non-linear method often used for visualization that preserves the local structure of the data in 2D or 3D space.\n",
        "\n",
        "You'll learn when and why to use each technique, and how to apply them to numerical data using scikit-learn.\n",
        "\n",
        "üìí Notebook Sections:\n",
        "\n",
        "1. Title & Introduction\n",
        "2. What is Dimensionality Reduction?\n",
        "3. Load and Prepare Data\n",
        "4. Apply PCA (Principal Component Analysis)\n",
        "5. Visualize PCA Output\n",
        "6. Apply TSNE (T-distributed Stochastic Neighbor Embedding)\n",
        "7. When to Use PCA vs TSNE\n",
        "8. Summary and What‚Äôs Next"
      ],
      "metadata": {
        "id": "ZTtR_Q7pwZU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Title & Introduction (Markdown Cell)\n",
        "### 08 ‚Äî Dimensionality Reduction with PCA and TSNE\n",
        "\n",
        "This notebook demonstrates how to reduce the number of features in a dataset using two popular techniques:\n",
        "\n",
        "- Principal Component Analysis (PCA)\n",
        "- T-SNE (T-distributed Stochastic Neighbor Embedding)\n",
        "\n",
        "Dimensionality reduction is useful when working with high-dimensional data, where visualizations or model performance may suffer due to the number of features.\n",
        "\n",
        "\n",
        "## 2. What is Dimensionality Reduction? (Markdown)\n",
        "### What is Dimensionality Reduction?\n",
        "\n",
        "Dimensionality reduction is the process of reducing the number of input variables (features) in your dataset while preserving as much useful information as possible.\n",
        "\n",
        "Why it‚Äôs useful:\n",
        "\n",
        "- Simplifies data visualization (e.g., reduce to 2D or 3D)\n",
        "- Removes noise and redundancy\n",
        "- Reduces overfitting risk\n",
        "- Improves model training time\n"
      ],
      "metadata": {
        "id": "A8UuBW9cxGlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load and Prepare Data"
      ],
      "metadata": {
        "id": "jSG3j8KXxyZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVEcek50wWS9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"../data/sample_data.csv\")\n",
        "\n",
        "# Select numeric features only for PCA/TSNE\n",
        "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "df_numeric = df[numeric_cols].dropna()  # Ensure no missing values\n",
        "\n",
        "df_numeric.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Apply PCA (Principal Component Analysis)"
      ],
      "metadata": {
        "id": "72I6u470xv84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA to reduce to 2 components\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(df_numeric)\n",
        "\n",
        "# Create DataFrame\n",
        "df_pca = pd.DataFrame(pca_result, columns=[\"PC1\", \"PC2\"])\n",
        "df_pca.head()"
      ],
      "metadata": {
        "id": "f78yXmy1xPj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualize PCA Output"
      ],
      "metadata": {
        "id": "m911jsmZxpYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_pca[\"PC1\"], df_pca[\"PC2\"], alpha=0.7)\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.title(\"PCA Result (2 Components)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T6-0OUtExPmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Apply TSNE (T-distributed Stochastic Neighbor Embedding)"
      ],
      "metadata": {
        "id": "zKuLs43ixjz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Apply TSNE for visualization\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "tsne_result = tsne.fit_transform(df_numeric)\n",
        "\n",
        "df_tsne = pd.DataFrame(tsne_result, columns=[\"TSNE1\", \"TSNE2\"])\n",
        "df_tsne.head()"
      ],
      "metadata": {
        "id": "Vhzl2jB7xPpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Visualize TSNE Output"
      ],
      "metadata": {
        "id": "KwRHeOP9xia_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_tsne[\"TSNE1\"], df_tsne[\"TSNE2\"], alpha=0.7)\n",
        "plt.xlabel(\"TSNE Component 1\")\n",
        "plt.ylabel(\"TSNE Component 2\")\n",
        "plt.title(\"TSNE Result (2 Components)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBkSKOmAxPrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. When to Use PCA vs TSNE (Markdown)\n",
        "### When to Use PCA vs TSNE\n",
        "\n",
        "**PCA**  \n",
        "- Linear technique  \n",
        "- Fast and interpretable  \n",
        "- Good for feature reduction and model input\n",
        "\n",
        "**TSNE**  \n",
        "- Non-linear technique  \n",
        "- Best for visualization only (not used for modeling)  \n",
        "- Slower and harder to interpret\n",
        "\n",
        "For model training: Use PCA  \n",
        "For data exploration/visualization: Use TSNE\n",
        "\n",
        "## 9. Summary and What‚Äôs Next (Markdown)\n",
        "### Summary\n",
        "\n",
        "- PCA reduces features by projecting data onto principal axes.\n",
        "- TSNE reduces data to 2D or 3D while preserving local relationships.\n",
        "- These tools help in visualizing and simplifying datasets with many features.\n",
        "\n",
        "Next up: We‚Äôll look at selecting the most relevant features using filter, wrapper, and embedded methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "3_JwIYEWxX1A"
      }
    }
  ]
}